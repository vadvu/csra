[{"path":"https://vadvu.github.io/csra/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 csra authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-1-equalparts","dir":"Articles","previous_headings":"","what":"Example 1: equalparts()","title":"Get started with csra","text":"basic example shows main (really powerful) function equalparts() works:  note section constructed follows: 1. Pearson’s r (note, Cor(X,Y)=Cov(X,Y)D(X)D(Y)Cor(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{D(X)D(Y)}} measures linear association) 2. Lower higher bound 95% CI correlation coefficient square brackets 3. p-value t-statistics brackets (, P(|t̂|>t0.975(n−1))P(|\\hat{t}|>t_{0.975}(n-1)) ). 4. χ2\\chi^2 statistics stars indicating p<0.01p<0.01 level significance (note, function ***p<0.01,**p<0.05,*p<0.1^{***}p<0.01, ^{**}p<0.05, ^{*}p<0.1 ). Plot returned default can easily changed ggplot2 syntax. Just save function output add ggplot2 blocks:  Also table results can returned, just set return_data = TRUE: columns table : 1. parts - equal subsample. case - sixtiles. 2. Freq_0 - number observations “0” values. 3. Freq_1 - number observations “1” values. 4. means - mean independent variable specific interval (equal part). (scatter plot Freq_1 means basic plot pictured earlier). 5. min - min value independent variable specific interval (equal part). 6. max - max value independent variable specific interval (equal part). 7. prc5 - 5 percentile value independent variable specific interval (equal part). 8. prc95 - 95 percentile value independent variable specific interval (equal part). 9. low95CI - lower Wald 95% interval (2.5%). Wald CI :π̂±za/2×π̂×(1−π̂)n\\hat{\\pi} \\pm z_{/2}\\times \\sqrt{\\frac{\\hat{\\pi}\\times(1-\\hat{\\pi})}{n}} π̂\\hat{\\pi} estimated probability, za/2=1.96z_{/2} = 1.96 due 95% CI. 10. high95CI - higher Wald 95% interval (97.5%).","code":"data(\"datex\") #it's an example panel \"long\" data that you can use  #Now let's try to analyze how VDEM democracy index affects revolutionary situations equalparts(   data = datex, #our data   independent = 'VDEM_v2x_polyarchy', #independent var   lag_independent = T, #Should it be lagged? Yes, because political regime can change dramatically during revolutionary year   lag_code = \"iso3\", #by what unit lag is realized (object from country-year, in our case it is iso3 code)   lead = T, #due to data specific in the top we have earlier data - 2019, 2018, 2017, ..., so `lead` should be used. Otherwise, False is needed   dependent = 'NVC_1.3_NONVIOL', #dependent var   n = 6, #number of equal parts. If n = 10, it is decile analysis, 4 - quartile analysis and etc   bar_or_scatter = 'scatter', #plot type, scatter is more powerful   regline = TRUE, #linear regression line   return_data = FALSE, #we want to see plot, so we do not need data   conf_bars = TRUE, #95%CI   range_bars = FALSE, #range (max-min) of independent var in each unit (for ex., decile)   save_plot = FALSE #we do not want to save plot, so its False ) library(ggplot2)  plot <- equalparts(   data = datex,   independent = 'VDEM_v2x_polyarchy',   lag_independent = T,   lag_code = \"iso3\",   lead = T,   dependent = 'NVC_1.3_NONVIOL',   n = 6,   bar_or_scatter = 'scatter',   regline = TRUE,   return_data = FALSE,   conf_bars = TRUE,   range_bars = FALSE,   save_plot = FALSE )  # for ex., change axis names and theme plot + xlab(\"x var name\") + ylab(\"y var name\") + theme_grey() equalparts(   data = datex,   independent = 'VDEM_v2x_polyarchy',   lag_independent = T,   lag_code = \"iso3\",   lead = T,   dependent = 'NVC_1.3_NONVIOL',   n = 6,   bar_or_scatter = 'scatter',   regline = TRUE,   return_data = TRUE, #here   conf_bars = TRUE,   range_bars = FALSE,   save_plot = FALSE ) #>    parts Freq_0 Freq_1      means   min   max  prc5 prc95     low95CI #> 7      1   1592     21 0.09029262 0.008 0.145 0.016 0.143 0.007487174 #> 8      2   1583     30 0.17917483 0.145 0.214 0.149 0.210 0.012005542 #> 9      3   1565     48 0.28196590 0.214 0.362 0.220 0.354 0.021465775 #> 10     4   1551     62 0.47658215 0.362 0.600 0.372 0.588 0.029055460 #> 11     5   1578     35 0.71369994 0.601 0.814 0.613 0.801 0.014588331 #> 12     6   1605      7 0.86508437 0.814 0.926 0.820 0.907 0.001132506 #>       high95CI #> 7  0.018551264 #> 8  0.025192226 #> 9  0.038050654 #> 10 0.047819928 #> 11 0.028809065 #> 12 0.007552358"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-2-sdiff","dir":"Articles","previous_headings":"","what":"Example 2: sdiff()","title":"Get started with csra","text":"function implements nonparametric test (alternative t-test) based Monte Carlo Simulations. idea straightforward. First, initial difference groups counted. Null hypothesis - difference equal zero, alternative hypothesis - difference significantly different zero. test hypothesis, iterative procedure created values groups randomly mixed (.e. observation can randomly assigned one groups). Due randomness, difference mean mixed groups zero. thousand procedures, construct distribution resulting differences simply compare observed difference. Consider following example: firstly simulate two random variables - XX YY. Lets assume show state-capacity index group countries never experienced revolutions (XX) index group countries experienced least one revolution history. want know - statistically significant difference. simulated example, X∼N(0.5,22)X \\sim N(0.5,2^2) Y∼N(2,22)Y \\sim N(2,2^2). , indeed difference means. Lets try statistically support .  Indeed, statistically significant difference one can reject H0H_0 acceptable confidence level.","code":"x = rnorm(50, 0.5, 2) #E(x) = 0.5 y = rnorm(50, 2, 2) #E(y) = 2 sdiff(y, x, n = 1000) #True E(y)-E(x) = 1.5"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-3-calibration","dir":"Articles","previous_headings":"","what":"Example 3: calibration()","title":"Get started with csra","text":"next function calibration() gives -sample calibration graph binary outcome models. words, tool model evaluation. logic test straighforward: Get estimated probabilities model sort bins equal width. default function makes 10 equal parts. bin, compute: () mean predicted probability (b) average fraction 1s Plot look systematic deviation 45 line. deviations, model good. function inspired Gary King, idea came lecture, changed little bit.","code":"logit <- glm(data = datex,               NVC_1.3_VIOL ~ UN_Total_Population_log + UN_Median_Age + VDEM_v2x_polyarchy_lag,              family = binomial(link = \"logit\"))  calibration(logit)"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-4-eba","dir":"Articles","previous_headings":"","what":"Example 4: eba()","title":"Get started with csra","text":"Extreme Boundary Analysis (EBA), proposed discussed view Sala--Martin (1997) subsequent modifications proposed authors (Hegre Sambanis 2006), method testing robustness estimate variable running models possible combinations variables.","code":"eba.out <- eba(y = \"NVC_1.3_VIOL\", #DV                x = \"UN_Median_Age\", #Var of interest                const = \"year\", #FE                 control = c(\"VDEM_v2x_polyarchy_lag\",                            \"UN_Total_Population_log\",                             \"One_more_var\",                             \"One_more_var\",                            \"One_more_var\"),                 data = datex,                 nvar = 3, #How many controls include in each model?                model = \"logit\",                 cl = NULL #Numver of engines to use, default is `NULL` for one engine                )"},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"goldstone-regime-type-classification","dir":"Articles","previous_headings":"Some additional functions","what":"Goldstone regime type classification","title":"Get started with csra","text":"Goldstone et al. (2010) proposed new regime type classification based Polity-V project. approach distinguishes five types political regimes based two indicators Polity database – EXREC (Executive Recruitment) PARCOMP (Competitiveness Political Participation). Function goldclass provide ability recode Polity-V data 5-class variable: 1. full autocracy 2. partial autocracy 3. partial democracy 4. partial democracy factionalism 5. full democracy","code":"polity5data$goldstone_regime <- goldclass(exrec = polity5data$exrec, parcomp = polity5data$parcomp)"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"fgls-model-for-estimated-dependent-variable","dir":"Articles","previous_headings":"Some additional functions","what":"FGLS model for estimated dependent variable","title":"Get started with csra","text":"edv.fgls function based completely following paper: Lewis, J. B., & Linzer, D. . (2005). Estimating regression models dependent variable based estimates. Political analysis, 13(4), 345-364. two possible strategies. variance yiy_i unknown, numeric vector number observations N=[n1,...,ni]N=[n_1,...,n_i] yiy_i estimated provided. example, yy - mean housholds income, n number housholds. second possible situation variance yiy_i known. case, provide DVvariance argument function numeric vector variances V=[v1,...,vi]V=[v_1,...,v_i].","code":"lm1 <- lm(estimated_y ~ x, data = data) corrected_model1 = edv.fgls(lm1, DVvariance = variance_y_vector) # if variance of each y is known corrected_model2 = edv.fgls(lm1, n = number_of_n_for_each_y_vector) # if variance of each y is unknwon"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Get started with csra","text":"Lewis, J. B., & Linzer, D. . (2005). Estimating regression models dependent variable based estimates. Political analysis, 13(4), 345-364. Hegre, H., & Sambanis, N. (2006). Sensitivity analysis empirical results civil war onset. Journal conflict resolution, 50(4), 508-535. Xavier X. Sala--Martin. (1997). Just Ran Two Million Regressions. American Economic Review, 87(2), 178–183.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"some-r","dir":"Articles","previous_headings":"","what":"Some R","title":"Materials for CSRA students/interns","text":"Rstudio Cheatsheet. Good practical books/resources statistics R: 1 - huge handbook lots examples explanations 2 - practical concise 3 - sociological statistics 4 - short handbook lots topics 5 - causality 5+ - theory math statistics Visualization R: 1, 2, 3. Research Design (must read least 1-10 chapters understand use statistic): 1 Intro logistic regression Also note extremely powerful package sjPlot provides regression tables, marginal effects, contingency tables etc.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"basics","dir":"Articles","previous_headings":"","what":"Basics","title":"Materials for CSRA students/interns","text":"Statistical inference? conclusion sample population based estimates model. Statistical estimation types : Interval (like confidence intervals)?: Sberbank’s price 340 360 rubbles 3 days 90% confidence. Point (like mean): Sberbank’s price 350 rubbles 3 days.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"expectation-ex-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Expectation E(X)E(X) properties","title":"Materials for CSRA students/interns","text":"E(c)=cE(c)=c, cc - const  E(cX)=c*E(X)E(cX)=c*E(X)  E(X+Y)=E(X)+E(Y)E(X+Y)=E(X)+E(Y)  X Y independent: E(XY)=E(X)*E(Y)E(XY)=E(X)*E(Y) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"variance-dxvarx-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Variance D(X)=Var(X)D(X)=Var(X) properties","title":"Materials for CSRA students/interns","text":"D(X)=E([X−E(X)]2)=E(X2)−E2(X)D(X)=E([X-E(X)]^2)=E(X^2)-E^2(X)  D(X)≥0D(X)\\geq 0  D(c)=0D(c)=0  D(cX)=c2D(X)D(cX)=c^2D(X)  D(X+c)=D(X)+0D(X+c)=D(X)+0 ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"covariance-covxy-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Covariance Cov(X,Y)Cov(X,Y) properties","title":"Materials for CSRA students/interns","text":"Cov(X,Y)=E[(X−E(X))*(Y−E(Y))]=E(XY)−E(X)E(Y)Cov(X,Y)=E[(X-E(X))*(Y-E(Y))]=E(XY)-E(X)E(Y)  Cov(X,X)=D(X)Cov(X,X)=D(X)  Cov(X,Y)=Cov(Y,X)Cov(X,Y)=Cov(Y,X)  Cov(X+Y,Z)=Cov(X,Z)+Cov(X,Z)Cov(X+Y,Z)=Cov(X,Z)+Cov(X,Z)  Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z)Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z)  Cov(cX,Y)=c*Cov(X,Y)Cov(cX,Y)=c*Cov(X,Y)  Cov(X,c)=0Cov(X,c)=0  Cov(X+c,Y)=Cov(X,Y)Cov(X+c,Y)=Cov(X,Y)  D(X±Y)=D(X)±2Cov(X,Y)+D(Y)D(X \\pm Y)=D(X)\\pm 2Cov(X,Y)+D(Y)  X Y independent: Cov(X,Y)=0Cov(X,Y)=0 D(X±Y)=D(X)±D(Y)D(X \\pm Y)=D(X)\\pm D(Y) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"correlation-corrxy-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Correlation Corr(X,Y)Corr(X,Y) properties","title":"Materials for CSRA students/interns","text":"Corr(X,Y)=Cov(X,Y)D(X)D(Y)Corr(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{D(X)}\\sqrt{D(Y)}}  |Corr(X,Y)|≤1|Corr(X,Y)|\\leq 1  X Y independent (linearly): Corr(X,Y)=0Corr(X,Y)=0  Corr(X,X)=1Corr(X,X)=1  Corr(X,Y)=1Corr(X,Y)=1 exist values ≠0a\\neq 0 bb Y=aX+=aX+b  Corr(X+c,Y)=Corr(X,Y)Corr(X+c,Y)=Corr(X,Y)  Corr(X*(±c),Y)=±Corr(X,Y)Corr(X*(\\pm c),Y)=\\pm Corr(X,Y) c=0:Corr(cX,Y)=0c=0:Corr(cX,Y)=0 ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"covariance-matrix","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Covariance matrix","title":"Materials for CSRA students/interns","text":"Assume matrix XX xijx_{ij} random variable: [x11…x1j⋮⋱⋮xi1…xij]\\begin{bmatrix}     x_{11} & \\dots & x_{1j} \\\\     \\vdots & \\ddots & \\vdots \\\\     x_{i1} & \\dots & x_{ij} \\\\ \\end{bmatrix} expectation matrix E(X)E(X) : [E(x11)…E(x1j)⋮⋱⋮E(xi1)…E(xij)]\\begin{bmatrix}     E(x_{11}) & \\dots & E(x_{1j}) \\\\     \\vdots & \\ddots & \\vdots \\\\     E(x_{i1}) & \\dots & E(x_{ij}) \\\\ \\end{bmatrix} Properties E(X)E(X) matrix: 1. B=[b1,...,bn]TB=[b_1, ..., b_n]^T constant-vector, E(B)=(B)=B 2. E(cX)=cE(X)E(cX)=cE(X), cc - constant term 3. E(X+Y)=E(X)+E(Y)E(X+Y)=E(X)+E(Y), XX YY random variables vectors 4. E(AX)=AE(X)E(AX)=AE(X) AA - matrix constant terms covariance random vector X=[x1,...,xi]TX=[x_1,...,x_i]^T V(X)V(X) (also might see another notation - ∑\\sum): V(X)=[Cov(x1,x1)…Cov(x1,xi)⋮⋱⋮Cov(xi,x1)…Cov(xi,xi)]=[Var(x1)…Cov(x1,xi)⋮⋱⋮Cov(xi,x1)…Var(xi)]V(X)=\\begin{bmatrix}     Cov(x_1, x_1) & \\dots & Cov(x_1,x_i) \\\\     \\vdots & \\ddots & \\vdots \\\\     Cov(x_i, x_1) & \\dots & Cov(x_i, x_i) \\\\ \\end{bmatrix}= \\begin{bmatrix}     Var(x_1) & \\dots & Cov(x_1,x_i) \\\\     \\vdots & \\ddots & \\vdots \\\\     Cov(x_i, x_1) & \\dots & Var(x_i) \\\\ \\end{bmatrix} quadratic symmetric matrix. X=[X1]X = [X_1] (one-dimensional random variable) V(X)=Cov(X1,X1)=Var(X1)V(X)=Cov(X_1,X_1)=Var(X_1)V(X)V(X) can written random-vector XX : V(X)=E[(X−E(X))*(X−E(X))T]V(X)=E[(X-E(X))*(X-E(X))^T] Properties V(X)V(X) matrix: 1. V(cX)=c2V(X)V(cX)=c^2V(X), cc constant term 2. V(X+B)=V(X)V(X+B)=V(X) BB constant-vector 3. V(AX)=AV(X)ATV(AX)=AV(X)^T AA constant matrix 4. Cov(cX,zX)=cV(X)zTCov(cX,zX)=cV(X)z^T","code":""},{"path":[]},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"model","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Model","title":"Materials for CSRA students/interns","text":"formula linear regression kk explanatory variables : yi=β0+∑kβkxi,k+ϵiy_i = \\beta_0+\\sum_k{\\beta_kx_{,k}}+\\epsilon_i yy dependent variable (outcome) try explain/predict independent (explanatory) variables xx. Basically, equation two parts: Systematic: β0+∑kβkxi,k\\beta_0+\\sum_k{\\beta_kx_{,k}} Stochastic: ϵi∼N(0,σ2)\\epsilon_i \\sim N(0,\\sigma^2) stochastic part fully random. understand another way, let reformulate formula: μi=β0+∑kβkxi,k\\mu_i=\\beta_0+\\sum_k{\\beta_kx_{,k}}yi∼N(μi,σ2)y_i \\sim N(\\mu_i,\\sigma^2) words, model try predict average values dependent variable assuming mean μ\\mu conditional independent factors xx. estimate parameters β\\beta? Turning technical issues, minimize RSS (Residuals Sum Squares) deviations modeled (predicted) values yy hat (ŷ\\hat y) observed (real) values yy. Note, ŷ=β0+∑kβkxi,k\\hat y=\\beta_0+\\sum_k{\\beta_kx_{,k}}, can write RSS : RSS=∑(yi−b1xi,1−...bkxi,k)2RSS=\\sum_i{(y_i-b_1x_{,1}-...b_kx_{,k}})^2 RSS=∑(yi−ŷ)2RSS=\\sum_i{(y_i-\\hat y_i)^2} Minimization sum (quadratic amount deviations modeled observable values) can done taking partial derivatives respect βk\\beta_k (lets write concise θ=[β1,β2,...βp]\\theta=[\\beta_1, \\beta_2, ... \\beta_p]) coefficients linear combination XX (matrix explanatory variables). matrix following view: [x11…x1j⋮⋱⋮xi1…xij]\\begin{bmatrix}     x_{11} & \\dots & x_{1j} \\\\     \\vdots & \\ddots & \\vdots \\\\     x_{i1} & \\dots & x_{ij} \\\\ \\end{bmatrix} columns jj variables rows ii units. example, units countries (Russia, USA, France) variables population democracy level. [0.89463715.220.27163715.220.905323348.65]\\begin{bmatrix}     0.894 &  63715.22 \\\\     0.271 & 63715.22 \\\\     0.905 & 323348.65 \\\\ \\end{bmatrix} Turning minimization respect θ\\theta parameters, system k equations form (example k=1k=1): ∑∂RSS∂β1=∑i2*(−xi,1)*(yi−β1xi,1−β2xi,2−...)=0\\sum_i{\\frac{\\partial RSS}{\\partial \\beta_1}}=\\sum_i{2*(-x_{,1})*(y_i-\\beta_1x_{,1}-\\beta_2x_{,2}-...)}=0 can rearranged (opening brackets dividing equations -2) : ∑ixi,12β1+∑(xi,2xi,1)β2+...=∑ixi,1yi\\sum_i{x_{,1}^2 \\beta_1}+\\sum_i{(x_{,2}x_{,1})\\beta_2}+...=\\sum_i{x_{,1}y_i} terms linear algebra equation: XTXθ=XTyX^TX\\theta=X^Ty one can find θ\\theta reformulating previous formula (multiply parts (XTX)−1(X^TX)^{-1} lefty, −1A=IA^{-1}=II unit matrix): θ=(XTX)−1XTy\\theta = (X^TX)^{-1}X^Ty equation one solution det[XTX]≠0det[X^TX]\\ne 0 (see Assumptions). full model : y=Xθ+ϵy=X\\theta+\\epsilon y=θTX+ϵy=\\theta^TX+\\epsilon","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"assumptions-gauss-markov-theorem","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Assumptions (Gauss-Markov theorem):","title":"Materials for CSRA students/interns","text":"Homoscedasticity: Var(ϵ|x)=constVar(\\epsilon|x)=const multicollinearity: Corr(x1,x2)≠0→Corr(x_1, x_2)\\neq0 \\inflated SE, robust results (drop observation significantly change θ\\theta estimates). case perfect multicollinearity (Corr=|1|Corr=|1|, dummy variable trap - just opposite dummies model), find estimation θ\\theta (find inverse matrix XTXX^TX due determinant equals 0) endogeneity: Corr(ϵi|ϵj)=0Corr(\\epsilon_i|\\epsilon_j)=0 E(ϵi|xi,j)=0E(\\epsilon_i|x_{,j})=0 Normality residuals E(ϵ)=0E(\\epsilon)=0 Thus, ϵi∼..d.N(0,σ2)\\epsilon_i \\sim ..d. N(0,\\sigma^2), ..di..d - identically independently distributed. Therefore, residuals covariance matrix V(ϵ)=σ2IV(\\epsilon)=\\sigma^2I","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"properties","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Properties:","title":"Materials for CSRA students/interns","text":"assumptions held, OLS estimation Best Linear Unbiased Estimator (BLUE). , : 1. efficient: min Var(θ̂)Var(\\hat \\theta) among possible linear unbiased estimates θ\\theta 2. unbiased: E(θ̂)=θE(\\hat \\theta)=\\theta 3. consistent:limn→infσ2(X(n)TX(n))jj−1=0\\lim_{n\\\\inf}{\\sigma^2(X^{(n)T}X^{(n)})^{-1}_{jj}}=0 limn→infVar(θ̂(n))=0\\lim_{n\\\\inf}{Var(\\hat \\theta_i^{(n)})}=0 E(θ̂(n))=θiE(\\hat \\theta_i^{(n)})=\\theta_i can just write: limn→inf(θ̂(n)−θi)=0\\lim_{n\\inf}{(\\hat \\theta^{(n)}_i-\\theta_i)}=0","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"standard-errors-and-significance","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Standard errors and significance:","title":"Materials for CSRA students/interns","text":"identifying θ̂\\hat{\\theta} significant calculate variance Var(θ̂)Var(\\hat{\\theta}). Lets find covariance matrix diagonal elements Cov(θi,θi)=Var(θi)Cov(\\theta_i,\\theta_i)=Var(\\theta_i): V(θ̂)=σ̂2(XTX)−1V(\\hat{\\theta})=\\hat{\\sigma}^2(X^TX)^{-1}σ̂2\\hat{\\sigma}^2 estimation Var(ϵ̂)Var(\\hat{\\epsilon}) estimated model Ŷ=Xθ̂\\hat{Y}=X\\hat{\\theta}. estimation can done using statistic : S2=RSSn−p=∑(yi−ŷ)2n−pS^2=\\frac{RSS}{n-p}=\\frac{\\sum_i{(y_i-\\hat y_i)^2}}{n-p} unbiased estimation Var(ϵ)Var(\\epsilon), E(S2)=Var(ϵ)E(S^2)=Var(\\epsilon). words, Sample Variance ϵ\\epsilon. model intercept, S2S^2 just usual sample variance yy. SE statistics calculation just diag[V(θ̂)]\\sqrt{diag[V(\\hat{\\theta})]}. statistic θ̂seθ̂\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}} known distribution (t-distribution). use θ̂seθ̂\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}} simply shows: θ̂−θ0seθ̂∼t(n−p)\\frac{\\hat{\\theta}-\\theta^0}{se_{\\hat{\\theta}}} \\sim t(n-p)θ̂0\\hat \\theta^0 shows value θ\\theta H0H_0. Usually 0, just θ̂seθ̂\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}}. possible use values θ̂0\\hat \\theta^0 test specific null hypotheses. example: H0:θ=1H_0: \\theta = 1 test statistic (works little bit complicated, logic basically like ): θ̂−θ0seθ̂=θ̂−1seθ̂\\frac{\\hat{\\theta}-\\theta^0}{se_{\\hat{\\theta}}}=\\frac{\\hat{\\theta}-1}{se_{\\hat{\\theta}}} identifying confidence interval θ̂\\hat\\theta: θ̂−t1−α/2Var(θ̂),θ̂+t1−α/2Var(θ̂)\\hat\\theta_i-t_{1-\\alpha/2}\\sqrt{Var(\\hat\\theta_i)}, \\hat\\theta_i+t_{1-\\alpha/2}\\sqrt{Var(\\hat\\theta_i)} words, population parameter θ\\theta lying estimated CI 100(1−α)100(1-\\alpha)% probability.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"significance-of-the-model","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Significance of the model:","title":"Materials for CSRA students/interns","text":"One wants test significance θi\\theta_i, whole model set estimated coefficients θ\\theta. Thus, joint test needed, null hypothesis : H0:θ0=θ1=...=θi=0H_0: \\theta_0=\\theta_1=...=\\theta_i=0 Thus, alternative hypothesis least one coefficient θi\\theta_i zero. One possible approach tests joint H0H_0 F-test. Assume linear model set coefficients pp number observations nn. test statistic FF : F=(RSSH0−RSS)/qRSS/(n−p)=ESS/(p−1)RSS/(n−p)∼F(p−1,n−p)F=\\frac{(RSS_{H_0}-RSS)/q}{RSS/(n-p)}=\\frac{ESS/(p-1)}{RSS/(n-p)} \\sim F(p-1,n-p) test basically compare null model (intercept ) estimated model, RSSRSS - residuals sum squares, ESSESS - explained sum squares (TSS−RSSTSS-RSS). statistic FF distribution p−1p-1 n−pn-p degrees freedom ϵi∼iidN(0,σ2)\\epsilon_i \\sim iid \\ N(0,\\sigma^2). Note, first expression can used test joint hypothesis H0H_0 coefficients, last one ESSESS can used H0H_0 coefficients assumed 0. first expression useful, ex., comparing two null-models. Assume model: y=θ0+θ1xi+θ2ki+θ3zi+ϵiy=\\theta_0+\\theta_1x_i+\\theta_2k_i + \\theta_3z_i+\\epsilon_i want test hypothesis : H0:θ2=θ3=0H_0:\\theta_2=\\theta_3=0 can use FF test, H0H_0 model yi=θ0+θ1xi+εiy_i=\\theta_0+\\theta_1x_i+\\varepsilon_i. parameter qq number tested null coefficients (precisely number linear restrictions model). example q=2q=2.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"endogeneity","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Endogeneity","title":"Materials for CSRA students/interns","text":"Statistical definition: 1. E(ϵ|X)≠0E(\\epsilon|X) \\ne 0 2. Corr(ϵ,X)≠0Corr(\\epsilon, X)\\ne0 words, ϵ\\epsilon independently distributed. Main sources endogeneity: Omitted variable problem. Omitted significant variable CC (appropriate control variable) effect Y (C→YC \\Y) effect X (C→XC \\X) Consequence - biased result XX model : y=β0+β1xy=\\beta_0+\\beta_1x Y→ZY \\Z X→ZX \\Z effect XX YY Consequence - biased result XX oue model : y=β0+β1x+β2zy=\\beta_0+\\beta_1x+\\beta_2z Reverse causality problem need controls (confounders)? Controls common variance (=effect) XX (independent variable) YY (dependent variable). get less biased estimates XX include controls, part common variance XX YY due confounders, including “clean” common variance XX YY “noise” produced factors. , “omitted variable bias” “backdoor” problem emerge resulting endogeneity biased, inconsistent inference.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"data-types","dir":"Articles","previous_headings":"Econometrics > Panel data","what":"Data types:","title":"Materials for CSRA students/interns","text":"Cross-section data - many units one time (GDP countries 2002): yi=ycountryy_i=y_{country} Time-series data - one unit time (GDP Russia 2002 2010): yt=yyeary_t=y_{year} Panel data - units repeated time: yi,t=ycountry,yeary_{,t}=y_{country,year} Pooled data - panel data researcher consider time spatial dependencies Cross-section data Time-series data Panel data (cross-section + time-series) Problems panel data: cross-sectional correlations (across units) autocorrelation (time) problem ignoring spatial time effects data special case general problem, omitting variables (endogeneity) Aggregation bias (Sympson paradox) serial correlations inconsistent SE →\\wrong statistical inference","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"fixed-effects-fe","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"Fixed-effects (FE)","title":"Materials for CSRA students/interns","text":"FE models can remove time-invariant omitted variables, unit-invariant omitted variables, variance outcome. ability FE model remove confounders side effect fact FE isolate particular dimensions variance data analyze. LSDV LSDV - Least Squares Dummy Variables model NN cross-sectional/time units): yi,t=β0+γ1d1,+...+γ(N−1)dN−1,+β1xi,t+εi,ty_{,t}=\\beta_0+\\gamma_1d_{1,}+...+\\gamma_{(N-1)}d_{N-1,}+\\beta_1x_{,t}+\\varepsilon_{,t} dd specific binary variable modeling unit-specific intercept. set dd countries want include FE cross-sectional dimension, di,1d_{,1} 1 country USA 0 otherwise. model assumes coefficients units different intercepts. Intercept β0\\beta_0 - average level yy reference cross-sectional/time unit. γ\\gamma - difference intercept reference unit unit. average difference yy unit reference category (also unit) variables equal. Error term structure: εi,t=εi+εt\\varepsilon_{,t} = \\varepsilon_i + \\varepsilon_t (cross-sectional variance + time dimension variance). FE models show? See Kropko Kubinec (2020) Unit FE: represents average effect unit-increase x y variable changes time, generalized cases (GDP increases country time, quality democracy change time?) Time FE: time FE coefficients represent average effect unit-increase x y variable changes case case, generalized across time points (much democratic wealthier countries poorer countries point time?)","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"random-effects-re","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"Random-effects (RE)","title":"Materials for CSRA students/interns","text":"Instead usual OLS equation LSDV OLS can use RE model random intercept: yij=β0j+β1xij+rijy_{ij}=\\beta_{0j}+\\beta_1 x_{ij}+r_{ij}β0j=γ00+u0j\\beta_{0j}=\\gamma_{00}+u_{0j} fist equation refers first-level (individuals ii), second refers second-level (clusters jj). rijr_{ij} - individual-level error term, u0ju_{0j} - cluster-level error term modeled random error cluster’s intercept individual level (random intercept). WjW_j affects intercept γ01\\gamma_{01} coefficient. γ00\\gamma_{00} - overall intercept. estimated intercepts assumed random drawings normal distribution thus can easily extended --sample groups Model Assumptions: rij∼..d.N(0,σ2)r_{ij} \\sim ..d. N(0, \\sigma^2), independent XX: E(rij|X,W)=0→E(r_{ij}|X,W)=0 \\tofirst-level exogeneity u0j∼..d.N(0,τ00)u_{0j} \\sim ..d. N(0, \\tau_{00}), independent XX: E(u0j|X,W)=0→E(u_{0j}|X,W)=0 \\tosecond-level exogeneity Corr(rij,u0j)=0Corr(r_{ij},u_{0j})=0 can combine -mentioned equations one: yij=γ00+β1xij+(u0j+rij)y_{ij}=\\gamma_{00}+\\beta_1 x_{ij}+(u_{0j}+r_{ij}) Thus, γ00\\gamma_{00} - usual intercept, εij\\varepsilon_{ij} decomposed across two independent source Random Variance - within (individual level) rijr_{ij} (clusters level) u0ju_{0j} clusters.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"fe-vs--re","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"FE vs. RE","title":"Materials for CSRA students/interns","text":"majority cases FE better RE due strict assumptions. assumptions held one chooses FE, estimates less efficient. However, one chooses RE instead FE assumptions true, estimates biased inconsistent. noted, strong assumptions endogeneity (individual + cluster endogeneity problem possible problem omitted variables either first second levels). However, lot cases RE appropriate: data hierarchy (nested clusters) want separate within variance cluster’s variables -> FE might perfect collinearity situation just 1 year observation (cluster unique value GDP -> perfect multicollinearity) sample fully random (surveys) cases - FE: “without analyzing contextual effects coefficient heterogeneity across higher-level units, ‘good old’ simple OLS regression cluster-robust standard errors fixed effects higher levels retained valid alternative MLM.” (Oshchepkov Shirokanova 2022) size clusters (number observation ) small better stable","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"limited-dv","dir":"Articles","previous_headings":"Econometrics","what":"Limited DV","title":"Materials for CSRA students/interns","text":"Limited Dependent Variables variables continuous, binary ordinal variables specific distributions. OLS fails predict model catch distributions. case binary data, OLS predicts 0.7, -0.3, 123 theoretically impossible values (lovers linear probability models). , linear estimation appropriate , finally, least-squares estimation bad approach.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"logistic-regression","dir":"Articles","previous_headings":"Econometrics > Limited DV","what":"Logistic regression","title":"Materials for CSRA students/interns","text":"Logistic regression models binary dependent variable using Logit link. Moreover, terms probabilities. Assume binary dependent variable YY follows Bernoulli distribution (special case binomial distribution 1 trial): Y∼(π[X])Y\\sim (\\pi[X]) probability getting “success” (“1”) π\\pi depends vector parameters XX. probability calculated logistic function: π(X)=exp(X)1+exp(X)\\pi(X)=\\frac{exp(X)}{1+exp(X)} π\\pi probability measures 0 1. One can see equation indeed π(x)\\pi(x) takes positive values (expexp) changes 0 1 (denominator always larger numerator addition unit). can rewrite function “regressive” way: π(X)=exp(Xθ)1+exp(Xθ)=11+exp(−Xθ)\\pi(X)=\\frac{exp(X\\theta)}{1+exp(X\\theta)}=\\frac{1}{1+exp(-X\\theta)} know probability function Bernoulli distribution : P(Yi|πi)=πiYi(1−πi)(1−Yi)P(Y_i|\\pi_i)=\\pi_i^{Y_i}(1-\\pi_i)^{(1-Y_i)} try estimate . analytical solution optimization, iterative process used Maximum Likelihood (ML) estimator LL assumption observations independence: L=∏inπiyi(1−πi)1−yiL=\\prod_i^n{\\pi_i^{y_i}(1-\\pi_i)^{1-y_i}} π\\pi calculated previous equation. optimization process product function sophisticated, make LL logarithmization take log-likelihood: l=∑[yiln(πi)+(1−yi)ln(1−πi)]l=\\sum_i^n [y_iln(\\pi_i)+(1-y_i)ln(1-\\pi_i)]l=∑[yiln(11+exp(−Xθ))+(1−yi)(11+exp(−Xθ))]l=\\sum_i^n[y_iln(\\frac{1}{1+exp(-X\\theta)})+(1-y_i)(\\frac{1}{1+exp(-X\\theta)})]l=∑[yiXθ−ln(1+exp(Xθ))]l=\\sum_i^n [y_i X\\theta-ln(1+exp(X\\theta))] estimation process simple, going discuss now. Simply put, ML works finding value θ̂\\hat{\\theta} gives maximum value function ll. θ̂\\hat{\\theta} consistent asymptotically efficient except perfect collinearity XX perfect discrimination 0 1. covariance matrix estimated : V(θ̂)=−1(θ̂)V(\\hat{\\theta})=^{-1}(\\hat{\\theta}) II information matrix calculated : (θ̂)=XTŴXI(\\hat{\\theta})=X^T \\hat{W}X Ŵ\\hat{W} estimated variance YY following diagonal matrix n*nn*n: [π1(1−π1)…0⋮⋱⋮0…πn(1−πn)]\\begin{bmatrix}     \\pi_{1}(1-\\pi_{1}) & \\dots & 0 \\\\     \\vdots & \\ddots & \\vdots \\\\     0 & \\dots & \\pi_{n}(1-\\pi_{n}) \\\\ \\end{bmatrix} Thus, finally : V(θ̂)=[∑inπi(1−πi)XTX]−1=V(\\hat{\\theta})=[\\sum_i^n{\\pi_i(1-\\pi_i)X^TX}]^{-1}==(XTŴX)−1=(X^T \\hat{W}X)^{-1} standard errors just squared root diagonal V(θ̂)V(\\hat{\\theta}) test statistic θ̂\\hat{\\theta} follows standard normal distribution calculated : θ̂seθ̂∼N(0,1)\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}} \\sim N(0,1)","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"rare-events-data","dir":"Articles","previous_headings":"","what":"Rare events data","title":"Materials for CSRA students/interns","text":"Revolutions, civil wars, defaults, coups rare events data can considered marginal unbalanced binary data due strong predominance one class (event). Therefore, specific methods required analyze (King Zeng 2001). One method logistic regression special version ML estimator (Kosmidis Firth 2009; King Zeng 2001) make consistent less biased case imbalanced data problem. One approach involves deliberately removing significant number ’0’s balance number observations classes (can achieved via mathcing procedures). approach enables use classical logistic regression without concern imbalance. nonparametric method, one can use random forest model quantile classifier (O’Brien & Ishwaran, 2019), specifically designed classifying unbalanced data. important note method allows avoidance assumptions form relationship. parametric models, authors assumed make assumption linearity, method, one can change form assumption simple operations variable, logarithmization representing factor polynomial. approach can lead reasonably accurate estimates. Next, discuss approach implemintation.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vadim Ustyuzhanin. Author, maintainer.","code":""},{"path":"https://vadvu.github.io/csra/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ustyuzhanin V (2024). csra: Analysis count data. R package version 1.2.2, https://vadvu.github.io/csra/.","code":"@Manual{,   title = {csra: Analysis of count data},   author = {Vadim Ustyuzhanin},   year = {2024},   note = {R package version 1.2.2},   url = {https://vadvu.github.io/csra/}, }"},{"path":"https://vadvu.github.io/csra/index.html","id":"csra","dir":"","previous_headings":"","what":"Analysis of count data","title":"Analysis of count data","text":"csra package functions used CSRA staff analyze political events. Now just functions (one demo stage now - better say, development stage), can used basic analysis. Additionally, near future new features added, see news section.","code":""},{"path":"https://vadvu.github.io/csra/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analysis of count data","text":"can install development version csra GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"vadvu/csra\")"},{"path":"https://vadvu.github.io/csra/index.html","id":"tutorial","dir":"","previous_headings":"","what":"Tutorial","title":"Analysis of count data","text":"examples csra usage one can find website Get started section. detailed information function can found section website.","code":""},{"path":"https://vadvu.github.io/csra/index.html","id":"contact-information","dir":"","previous_headings":"","what":"Contact Information","title":"Analysis of count data","text":"comments csra (suggestions development, bug fixes, etc.), please, feel free contact via email: vvustiuzhanin@yandex.ru","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":null,"dir":"Reference","previous_headings":"","what":"U-shape test for rare events logistic regression — U_shape_test","title":"U-shape test for rare events logistic regression — U_shape_test","text":"U-shape test rare events logistic regression","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"U-shape test for rare events logistic regression — U_shape_test","text":"","code":"U_shape_test(   data,   dep,   ind,   cnt,   mod = \"brglm\",   boot = c(\"none\", \"nonparam\", \"factor\"),   factor = NULL,   n = 1000,   HC = T,   const = T,   table_remove = NULL,   plot = F,   tab_save = F )"},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"U-shape test for rare events logistic regression — U_shape_test","text":"data Dataframe dep Character. Dependent variable. ind Character. Independent variable. cnt Vector characters names control variables. mod Character. Type model (now just brglm supported) boot Character. middle point \"lines\" calculated via bootstrap? - \"none\", yes - one can choose bootstrap type factor Character. boot = \"factor\". n Number bootstrap draws HC Logical. heteroscedasticity-consistent SE used? const Logical. constant included models? table_remove Vector variables names excluded regression table. plot Logical. plot depicted? tab_save Logical. table saved? yes - table saved working directory.","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"U-shape test for rare events logistic regression — U_shape_test","text":"Plot regression table u-shape test summary.","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"U-shape test for rare events logistic regression — U_shape_test","text":"Lind, J. T., & Mehlum, H. (2010). without U? appropriate test U‐shaped relationship. Oxford bulletin economics statistics, 72(1), 109-118. Simonsohn, U. (2018). Two lines: valid alternative invalid testing U-shaped relationships quadratic regressions. Advances Methods Practices Psychological Science, 1(4), 538-555.","code":""},{"path":"https://vadvu.github.io/csra/reference/calibration.html","id":null,"dir":"Reference","previous_headings":"","what":"In-sample calibration graph for binary outcome models — calibration","title":"In-sample calibration graph for binary outcome models — calibration","text":"-sample calibration graph binary outcome models","code":""},{"path":"https://vadvu.github.io/csra/reference/calibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"In-sample calibration graph for binary outcome models — calibration","text":"","code":"calibration(model, ns = 10)"},{"path":"https://vadvu.github.io/csra/reference/calibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"In-sample calibration graph for binary outcome models — calibration","text":"model model ns numver bins","code":""},{"path":"https://vadvu.github.io/csra/reference/calibration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"In-sample calibration graph for binary outcome models — calibration","text":"ggplot2 graph","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":null,"dir":"Reference","previous_headings":"","what":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"Data revolutionary campaigns democracy index, 1901-2019","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"","code":"datex"},{"path":[]},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"datex-a-data-frame-with-rows-and-columns-","dir":"Reference","previous_headings":"","what":"datex A data frame with 9,836 rows and 6 columns:","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"iso3 Country code \"iso3c\" format year Year NVC_1.3_NONVIOL Binary indicator. protestors primary use nonviolent tactic? 1 = Yes NVC_1.3_VIOL Binary indicator. protestors primary use violent tactic? 1 = Yes VDEM_v2x_polyarchy Electoral democracy index (0,1) V-Dem project VDEM_v2x_polyarchy_lag Electoral democracy index (0,1) time t-1 country ","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"NAVCO 1.3, VDEM","code":""},{"path":"https://vadvu.github.io/csra/reference/eba.html","id":null,"dir":"Reference","previous_headings":"","what":"Extreme boundary analysis for binary outcome — eba","title":"Extreme boundary analysis for binary outcome — eba","text":"Extreme boundary analysis binary outcome","code":""},{"path":"https://vadvu.github.io/csra/reference/eba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extreme boundary analysis for binary outcome — eba","text":"","code":"eba(y, x, const, control, data, nvar, model = \"logit\", cl = NULL)"},{"path":"https://vadvu.github.io/csra/reference/eba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extreme boundary analysis for binary outcome — eba","text":"y Character. Dependent variable. x Character. Independent variable. const Array characters. Set constant controls. control Array characters. Set controls. data Dataframe. nvar Number. Number control variables (including constant controls) make combinations. model Model type. Now \"logit\" logistic regression supported. cl Number. Number clusters use computations. Default NULL 1 cluster.","code":""},{"path":"https://vadvu.github.io/csra/reference/eba.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extreme boundary analysis for binary outcome — eba","text":"Dataframe results","code":""},{"path":"https://vadvu.github.io/csra/reference/edv.fgls.html","id":null,"dir":"Reference","previous_headings":"","what":"FGLS model for estimated dependent variable — edv.fgls","title":"FGLS model for estimated dependent variable — edv.fgls","text":"FGLS model estimated dependent variable","code":""},{"path":"https://vadvu.github.io/csra/reference/edv.fgls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"FGLS model for estimated dependent variable — edv.fgls","text":"","code":"edv.fgls(ols, DVvariance = NULL, n = NULL)"},{"path":"https://vadvu.github.io/csra/reference/edv.fgls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"FGLS model for estimated dependent variable — edv.fgls","text":"ols Initial OLS model (lm R) DVvariance Numeric vector variances y. length equal number observations initial model. n Numeric vector number observations (n) y estimated. length equal number observations initial model.","code":""},{"path":"https://vadvu.github.io/csra/reference/edv.fgls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"FGLS model for estimated dependent variable — edv.fgls","text":"re-estimated model","code":""},{"path":"https://vadvu.github.io/csra/reference/edv.fgls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"FGLS model for estimated dependent variable — edv.fgls","text":"function based completely following paper: Lewis, J. B., & Linzer, D. . (2005). Estimating regression models dependent variable based estimates. Political analysis, 13(4), 345-364. two possible strategies. variance y unknown, Numeric vector number observations (n) y estimated provided. example, y - mean housholds income, n number housholds. second possible situation variance y known. case, provide DVvariance arguement function numeric vector variances (case first situation number observations)","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of a binary data by dividing independent into equal parts — equalparts","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"Analysis binary data dividing independent equal parts","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"","code":"equalparts(   data,   independent,   lag_independent = FALSE,   lag_code,   lead = TRUE,   dependent,   n = 6,   nominal_or_percent = \"nominal\",   bar_or_scatter = \"bar\",   regline = TRUE,   range_bars = FALSE,   conf_bars = TRUE,   return_data = FALSE,   save_plot = FALSE,   name_save_plot = \"plot\" )"},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"data Dataframe independent Character. Independent variable. lag_independent Logical. independent variable lagged 1 time-unit? lag_code Character. Passed lag_independent False. name variable dataframe subject data. ex., country name, iso3 etc. lead Logical. Passed lag_independent False. lead used instead lag? Lead used case, data's top earlier time units (ex., 2022, 2021, 2020, ...). Lag used data's top starts later time units (1900, 1901, ...). dependent Character. Dependent variable. n Int. Number equal parts independent variable divided. nominal_or_percent Logical. output y-axis (intensity dependent variable) percents nominal values? want scatter plot automatically changed nominal. bar_or_scatter Character 2 possible values: \"bar\", \"scatter\". Type figure plotted. regline Logical. linear regression line plotted? range_bars Logical. range bars shown? Range depicts min max value independent variable divided group. conf_bars Logical. confidence bars shown? depict 95%CI binary dependent variable. return_data Logical. returned data (table)? False, plot returned. save_plot Logical. plot saved working directory? name_save_plot Character. Passed save_plot False. Name plot saving.","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"Plot (bar scatter) dataframe. dataframe following columns: parts: number equal part. first lowest values, last highest values Freq_0: number 0 cases dependent variable Freq_1: number 1 cases dependent variable means: mean independent variable specific equal part min: min value independent variable specific equal part max: max value independent variable specific equal part prc5: 5% percentile independent variable specific equal part prc95: 95% percentile independent variable specific equal part low95CI: lower border 95% CI Freq_1 high95CI: higher border 95% CI Freq_1","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"","code":"data(\"datex\") equalparts(data = datex, independent = 'VDEM_v2x_polyarchy_lag', lag_independent = FALSE, dependent = 'NVC_1.3_NONVIOL', n = 6, bar_or_scatter = 'scatter', regline= TRUE, return_data = FALSE, conf_bars = TRUE, range_bars = FALSE, save_plot = FALSE)   equalparts(data = datex, independent = 'VDEM_v2x_polyarchy', lag_independent = TRUE, lag_code = \"iso3\", lead = TRUE, dependent = 'NVC_1.3_NONVIOL', n = 10, bar_or_scatter = 'bar', nominal_or_percent = \"percent\", return_data = FALSE, conf_bars = TRUE, save_plot = TRUE, name_save_plot = \"figure1\")"},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Goldstone claasification of regime types based on Polity-V variables — goldclass","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"Goldstone claasification regime types based Polity-V variables","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"","code":"goldclass(exrec, parcomp)"},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"exrec array EXREC variable Polity-V project parcomp array PARCOMP variable Polity-V project","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"array Goldstone classification: 1 = full autocracy 2 = partial autocracy 3 = partial democracy 4 = partial democracy factionalism 5 = full democracy","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"Goldstone, J.., Bates, R.H., Epstein, D.L., Gurr, T.R., Lustik, M.B., Marshall, M.G., Ulfelder, J. & Woodward, M. (2010). Global Model Forecasting Political Instability. American Journal Political Science, 54, 190–208.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":null,"dir":"Reference","previous_headings":"","what":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"database revolutionary events 21st century prepared within framework project “Quantitative Analysis Forecasting Risks Socio-Political Destabilization Countries Afrasian Macrozone Instability” supported Russian Science Foundation (project . 18-18-00254-P). database describes revolutionary events 21st century various characteristics: chronological, geographical, type protestors' tactics, purpose degree success.","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"","code":"revolutions"},{"path":[]},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"revolutions-a-data-frame-with-event-as-unit-of-analysis-","dir":"Reference","previous_headings":"","what":"revolutions A data frame with event as unit of analysis.","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"n unique episode number start_year event start year end_year event end year country country name iso3c three-letter ISO 3166-1 alpha-3 (iso3c) country code region region country event took place belongs (UN Subregion classification) successful complete success (1 = yes, 0 = ) limited limited success (1 = yes, 0 = ) failed fail (1 = yes, 0 = ) ongoing episode still ended? (1 = yes, 0 = ). Note, episode can ongoing \"success\" coding preliminary estimate. armed armed tactic: fabric weapons (1 = yes, 0 = ) unarmed unarmed tactic: nonviolent resistance improvised weapons - sticks, stones (1 = yes, 0 = ) regime_change goal regime change (1 = yes, 0 = ) islamistic goal connected Islam (1 = yes, 0 = ). Note, feature usually goes regime change goal democratic goal establish/improve democratic institutions (1 = yes, 0 = ). Note, feature usually goes regime change goal social goal primary social, firstly connected life-conditions (1 = yes, 0 = ) separatism goal gain independence/autonomy (1 = yes, 0 = ) goal (1 = yes, 0 = ). Can overlapped mentioned goal types coupvolution event ended \"End game Coup\"? (1 = yes, 0 = ) revolutions event pure revolution (mass mobilization, aim overthrough regime)? (1 = yes, 0 = ) revolutions_plus_question event pure revolution, can still considered revolutionary movement? (1 = yes, 0 = ) types event including quasi-revolutionary events (one unique value = 1) ethnic episode connected ethnic cleaveges? (1 = yes, 0 = )","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"Center Stability Risk Analysis","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonparametric test for comparing means in 2 groups — sdiff","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"Nonparametric test comparing means 2 groups","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"","code":"sdiff(x, y, n = 1000)"},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"x Numeric array observations first group. y Numeric array observations second group. n Number simulations constriction Null hypothesis area. Default n=1000","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"ggplot","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"nonparametric test (alternative t-test) based Monte Carlo Simulations. idea straightforward. First, initial difference groups counted. Null hypothesis - difference equal zero, alternative hypothesis - difference significantly different zero. test hypothesis, iterative procedure created values groups randomly mixed (.e. observation can randomly assigned one groups). Due randomness, difference mean mixed groups zero. thousand procedures, construct distribution resulting differences simply compare observed difference.","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"","code":"x = rnorm(1000, 10, 10) y = rnorm(1000, 11, 2) sdiff(x, y, n = 1000) #> Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. #> ℹ Please use `after_stat(density)` instead. #> ℹ The deprecated feature was likely used in the csra package. #>   Please report the issue to the authors. #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":[]},{"path":"https://vadvu.github.io/csra/news/index.html","id":"csra-112","dir":"Changelog","previous_headings":"","what":"csra 1.1.2","title":"csra 1.1.2","text":"fixes U-shape, adding goldclass function. Plans: 1. Conceptually change U-shape 2. Add example section usage packages (students)","code":""}]
