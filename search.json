[{"path":"https://vadvu.github.io/csra/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 csra authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-1-equalparts","dir":"Articles","previous_headings":"","what":"Example 1: equalparts()","title":"Get started with csra","text":"basic example shows main (really powerful) function equalparts() works:  note section constructed follows: 1. Pearson’s r (note, \\(Cor(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{D(X)D(Y)}}\\) measures linear association) 2. Lower higher bound 95% CI correlation coefficient square brackets 3. p-value t-statistics brackets (, \\(P(|\\hat{t}|>t_{0.975}(n-1))\\) ). 4. \\(\\chi^2\\) statistics stars indicating \\(p<0.01\\) level significance (note, function \\(^{***}p<0.01, ^{**}p<0.05, ^{*}p<0.1\\) ). Plot returned default can easily changed ggplot2 syntax. Just save function output add ggplot2 blocks:  Also table results can returned, just set return_data = TRUE: columns table : 1. parts - equal subsample. case - sixtiles. 2. Freq_0 - number observations “0” values. 3. Freq_1 - number observations “1” values. 4. means - mean independent variable specific interval (equal part). (scatter plot Freq_1 means basic plot pictured earlier). 5. min - min value independent variable specific interval (equal part). 6. max - max value independent variable specific interval (equal part). 7. prc5 - 5 percentile value independent variable specific interval (equal part). 8. prc95 - 95 percentile value independent variable specific interval (equal part). 9. low95CI - lower Wald 95% interval (2.5%). Wald CI :\\[\\hat{\\pi} \\pm z_{/2}\\times \\sqrt{\\frac{\\hat{\\pi}\\times(1-\\hat{\\pi})}{n}}\\] \\(\\hat{\\pi}\\) estimated probability, \\(z_{/2} = 1.96\\) due 95% CI. 10. high95CI - higher Wald 95% interval (97.5%).","code":"data <- data(\"dataex\") #it's an example panel \"long\" data that you can use  #Now let's try to analyze how VDEM democracy index affects revolutionary situations equalparts(   data = datex, #our data   independent = 'VDEM_v2x_polyarchy', #independent var   lag_independent = T, #Should it be lagged? Yes, because political regime can change dramatically during revolutionary year   lag_code = \"iso3\", #by what unit lag is realized (object from country-year, in our case it is iso3 code)   lead = T, #due to data specific in the top we have earlier data - 2019, 2018, 2017, ..., so `lead` should be used. Otherwise, False is needed   dependent = 'NVC_1.3_NONVIOL', #dependent var   n = 6, #number of equal parts. If n = 10, it is decile analysis, 4 - quartile analysis and etc   bar_or_scatter = 'scatter', #plot type, scatter is more powerful   regline = TRUE, #linear regression line   return_data = FALSE, #we want to see plot, so we do not need data   conf_bars = TRUE, #95%CI   range_bars = FALSE, #range (max-min) of independent var in each unit (for ex., decile)   save_plot = FALSE #we do not want to save plot, so its False ) library(ggplot2) data(\"datex\")  plot <- equalparts(   data = datex,   independent = 'VDEM_v2x_polyarchy',   lag_independent = T,   lag_code = \"iso3\",   lead = T,   dependent = 'NVC_1.3_NONVIOL',   n = 6,   bar_or_scatter = 'scatter',   regline = TRUE,   return_data = FALSE,   conf_bars = TRUE,   range_bars = FALSE,   save_plot = FALSE )  # for ex., change axis names and theme plot + xlab(\"x var name\") + ylab(\"y var name\") + theme_grey() equalparts(   data = datex,   independent = 'VDEM_v2x_polyarchy',   lag_independent = T,   lag_code = \"iso3\",   lead = T,   dependent = 'NVC_1.3_NONVIOL',   n = 6,   bar_or_scatter = 'scatter',   regline = TRUE,   return_data = TRUE, #here   conf_bars = TRUE,   range_bars = FALSE,   save_plot = FALSE ) #>    parts Freq_0 Freq_1      means   min   max  prc5 prc95     low95CI #> 7      1   1592     21 0.09029262 0.008 0.145 0.016 0.143 0.007487174 #> 8      2   1583     30 0.17917483 0.145 0.214 0.149 0.210 0.012005542 #> 9      3   1565     48 0.28196590 0.214 0.362 0.220 0.354 0.021465775 #> 10     4   1551     62 0.47658215 0.362 0.600 0.372 0.588 0.029055460 #> 11     5   1578     35 0.71369994 0.601 0.814 0.613 0.801 0.014588331 #> 12     6   1605      7 0.86508437 0.814 0.926 0.820 0.907 0.001132506 #>       high95CI #> 7  0.018551264 #> 8  0.025192226 #> 9  0.038050654 #> 10 0.047819928 #> 11 0.028809065 #> 12 0.007552358"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-2-sdiff","dir":"Articles","previous_headings":"","what":"Example 2: sdiff()","title":"Get started with csra","text":"function implements nonparametric test (alternative t-test) based Monte Carlo Simulations. idea straightforward. First, initial difference groups counted. Null hypothesis - difference equal zero, alternative hypothesis - difference significantly different zero. test hypothesis, iterative procedure created values groups randomly mixed (.e. observation can randomly assigned one groups). Due randomness, difference mean mixed groups zero. thousand procedures, construct distribution resulting differences simply compare observed difference. Consider following example: firstly simulate two random variables - \\(X\\) \\(Y\\). Lets assume show state-capacity index group countries never experienced revolutions (\\(X\\)) index group countries experienced least one revolution history. want know - statistically significant difference. simulated example, \\(X \\sim N(0.5,2^2)\\) \\(Y \\sim N(2,2^2)\\). , indeed difference means. Lets try statistically support .  Indeed, statistically significant difference one can reject \\(H_0\\) acceptable confidence level.","code":"x = rnorm(50, 0.5, 2) y = rnorm(50, 2, 2) sdiff(x, y, n = 1000)"},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"example-3-u_shape_test","dir":"Articles","previous_headings":"","what":"Example 3: U_shape_test()","title":"Get started with csra","text":"Another function (DEMO stage) U_shape_test(), aims detect hump-shaped forms links. Currently, rare events logistic model implemented, although logic suitable GLMs. U-shape? Simply put, link variables similar parabola. Usually, modeled polynomial term regression equitation, ’s one option. really important case U-shape one extreme point (parabola ). Moreover, slope curve positive (negative) interval \\([x_{min},x_{midpoint}]\\) negative (positive) interval \\([x_{midpoint},x_{max}]\\). Let’s say equation:\\[y_i = \\beta_0 + \\beta_1\\times x_i + \\beta_2\\times f(x_i) + \\sum_{}^{} \\beta_k \\times z_{,k} + \\varepsilon_i\\] \\(\\beta_k\\) coefficients, \\(x\\) variable interest assume U-shape relationship \\(y\\) part formula: \\(\\beta_1\\times x_i + \\beta_2\\times f(x_i)\\), \\(z_{k}\\) control variables, \\(y\\) dependent variable \\(\\varepsilon\\) error term. definition U-shape described earlier, inequality implied:\\[\\beta_1 + \\beta_2\\times f'(x_i \\[x_{min},x_{midpoint}]) <0<\\beta_1 + \\beta_2\\times f'(x_i \\[x_{midpoint}, x_{max}])\\] condition can reformulated 2 hypotheses subsampled models:\\[y_i = \\beta_0 + \\beta_{lower}\\times x_i + \\sum_{}^{} \\beta_k \\times z_{,k} + \\varepsilon_i, x \\[x_{min},x_{midpoint}] (1)\\] \\[y_i = \\beta_0 + \\beta_{higher}\\times x_i + \\sum_{}^{} \\beta_k \\times z_{,k} + \\varepsilon_i, x \\[x_{midpoint}, x_{max}] (2)\\] hypotheses (inverse U-shape): + \\(H_L: \\beta_{lower}>0\\), equitation 1 + \\(H_H: \\beta_{higher}<0\\), equitation 2 method function U_shape_test() operates complicated following way: 1. full model estimated sample polynomial term. Let’s say :\\[y_i = \\beta_0 + \\beta_1\\times x_i + \\beta_2\\times x_i^2 + \\sum_{}^{} \\beta_k \\times z_{,k} + \\varepsilon_i\\] \\(\\beta_k\\) coefficients, \\(x\\) variable interest assume U-shape relationship \\(y\\), \\(z_{k}\\) control variables, \\(y\\) dependent variable \\(\\varepsilon\\) error term. 2. Divide sample two subsamples - first midpoint (identified vertex parabola polynomial term: \\(\\frac{-\\beta_1}{2\\times \\beta_2}\\)), second . 3. Estimate two models two subsamples. hump-shaped relationship assumes ascending descending part. , order test hump, necessary significant positive negative coefficients first second subsample respectively. 4. semiparametric model estimated without assumptions form link. GAM method used purpose. variable interest modelled smooth term using cubic splines variables modelled using parametric regressions. case :\\[y_i = \\beta_0 + f(x_i) + \\sum_{}^{} \\beta_k \\times z_{,k} + \\varepsilon_i\\] \\(f(x_i)\\) smooth term. 5. ANOVA test model polynomial term (1st step) GAM model (4th step). test needed identify whether polynomial term provides better worse fit link found GAM splines. \\(p > 0.1\\), polynomial considered good approximation. 6. Bootstrap midpoint (\\(\\frac{-\\beta_1}{2\\times \\beta_2}\\)) constructing CI. optional, highly recommended stage. Now works unstable function… 7. final stage.polynomial term significant (1st stage) significant opposite signs subsamples (2nd stage), GAM term significant terms EDF significance (4th stage), ANOVA test’s p-value greater 0.1 (5th stage), exists hump-shaped U-shaped link variables. case, polynomial term suitable approximating relationship. approach based 2 papers define overall strategy identifying U-shaped relationship continuous data (.e. linear regression model): - Lind, J. T., & Mehlum, H. (2010). without U? appropriate test U‐shaped relationship. Oxford bulletin economics statistics, 72(1), 109-118. - Simonsohn, U. (2018). Two lines: valid alternative invalid testing U-shaped relationships quadratic regressions. Advances Methods Practices Psychological Science, 1(4), 538-555.","code":"U_shape_test(   data = datex, #our data   dep = \"NVC_1.3_NONVIOL\", #dependent variable   ind = \"VDEM_v2x_polyarchy_lag\", #independent var   cnt = c(\"UN_Median_Age\", \"UN_Total_Population_log\"), #control vars   boot = \"none\", #bootstrap for middle point analysis - we do not use it in an example    n = 1000, #number of bootstrap deaws   const = T, #We need constan in a model   HC = T, #type of SE   plot = T,   tab_save = FALSE #we do not need to save regression table ) #>  #> ====================================================== #>                                Dependent variable:     #>                            --------------------------- #>                                                        #> ------------------------------------------------------ #> VDEM_v2x_polyarchy_lag              8.544***           #>                                      (1.328)           #> I(VDEM_v2x_polyarchy_lag2)         -10.989***          #>                                      (1.461)           #> UN_Median_Age                       0.044***           #>                                      (0.011)           #> UN_Total_Population_log             0.351***           #>                                      (0.045)           #> Constant                            -8.941***          #>                                      (0.519)           #> ------------------------------------------------------ #> N                                     8400             #> AIC                                  1768.79           #> U-shape test:                                          #> Extremum                              0.39             #> Xlower                          2.49 (p = 0.0065)      #> Xhigher                           -5.62 (p = 0)        #> GAM edf                           3.16 (p = 0)         #> AIC glm - AIC gam                     -2.84            #> ====================================================== #> Note:                      *p<0.1; **p<0.05; ***p<0.01"},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/csra.html","id":"goldstone-regime-type-classification","dir":"Articles","previous_headings":"Some additional functions","what":"Goldstone regime type classification","title":"Get started with csra","text":"Goldstone et al. (2010) proposed new regime type classification based Polity-V project. approach distinguishes five types political regimes based two indicators Polity database – EXREC (Executive Recruitment) PARCOMP (Competitiveness Political Participation). Function goldclass provide ability recode Polity-V data 5-class variable: 1. full autocracy 2. partial autocracy 3. partial democracy 4. partial democracy factionalism 5. full democracy","code":"polity5data$goldstone_regime <- goldclass(exrec = polity5data$exrec, parcomp = polity5data$parcomp)"},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"some-r","dir":"Articles","previous_headings":"","what":"Some R","title":"Materials for CSRA students/interns","text":"Rstudio Cheatsheet. Good practical books/resources statistics R: 1 - huge handbook lots examples explanations 2 - practical concise 3 - sociological statistics 4 - short handbook lots topics 5 - causality 5+ - theory math statistics Visualization R: 1, 2, 3. Research Design (must read least 1-10 chapters understand use statistic): 1 Intro logistic regression Also note extremely powerful package sjPlot provides regression tables, marginal effects, contingency tables etc.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"basics","dir":"Articles","previous_headings":"","what":"Basics","title":"Materials for CSRA students/interns","text":"Statistical inference? conclusion sample population based estimates model. Statistical estimation types : Interval (like confidence intervals)?: Sberbank’s price 340 360 rubbles 3 days 90% confidence. Point (like mean): Sberbank’s price 350 rubbles 3 days.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"expectation-ex-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Expectation \\(E(X)\\) properties","title":"Materials for CSRA students/interns","text":"\\(E(c)=c\\), \\(c\\) - const  \\(E(cX)=c*E(X)\\)  \\(E(X+Y)=E(X)+E(Y)\\)  X Y independent: \\(E(XY)=E(X)*E(Y)\\) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"variance-dxvarx-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Variance \\(D(X)=Var(X)\\) properties","title":"Materials for CSRA students/interns","text":"\\(D(X)=E([X-E(X)]^2)=E(X^2)-E^2(X)\\)  \\(D(X)\\geq 0\\)  \\(D(c)=0\\)  \\(D(cX)=c^2D(X)\\)  \\(D(X+c)=D(X)+0\\) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"covariance-covxy-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Covariance \\(Cov(X,Y)\\) properties","title":"Materials for CSRA students/interns","text":"\\(Cov(X,Y)=E[(X-E(X))*(Y-E(Y))]=E(XY)-E(X)E(Y)\\)  \\(Cov(X,X)=D(X)\\)  \\(Cov(X,Y)=Cov(Y,X)\\)  \\(Cov(X+Y,Z)=Cov(X,Z)+Cov(X,Z)\\)  \\(Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z)\\)  \\(Cov(cX,Y)=c*Cov(X,Y)\\)  \\(Cov(X,c)=0\\)  \\(Cov(X+c,Y)=Cov(X,Y)\\)  \\(D(X \\pm Y)=D(X)\\pm 2Cov(X,Y)+D(Y)\\)  X Y independent: \\(Cov(X,Y)=0\\) \\(D(X \\pm Y)=D(X)\\pm D(Y)\\) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"correlation-corrxy-properties","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Correlation \\(Corr(X,Y)\\) properties","title":"Materials for CSRA students/interns","text":"\\(Corr(X,Y)=\\frac{Cov(X,Y)}{\\sqrt{D(X)}\\sqrt{D(Y)}}\\)  \\(|Corr(X,Y)|\\leq 1\\)  X Y independent (linearly): \\(Corr(X,Y)=0\\)  \\(Corr(X,X)=1\\)  \\(Corr(X,Y)=1\\) exist values \\(\\neq 0\\) \\(b\\) \\(Y=aX+b\\)  \\(Corr(X+c,Y)=Corr(X,Y)\\)  \\(Corr(X*(\\pm c),Y)=\\pm Corr(X,Y)\\) \\(c=0:Corr(cX,Y)=0\\) ","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"covariance-matrix","dir":"Articles","previous_headings":"Basics > Notation and basic concepts:","what":"Covariance matrix","title":"Materials for CSRA students/interns","text":"Assume matrix \\(X\\) \\(x_{ij}\\) random variable: \\[\\begin{bmatrix}     x_{11} & \\dots & x_{1j} \\\\     \\vdots & \\ddots & \\vdots \\\\     x_{i1} & \\dots & x_{ij} \\\\ \\end{bmatrix}\\] expectation matrix \\(E(X)\\) : \\[\\begin{bmatrix}     E(x_{11}) & \\dots & E(x_{1j}) \\\\     \\vdots & \\ddots & \\vdots \\\\     E(x_{i1}) & \\dots & E(x_{ij}) \\\\ \\end{bmatrix}\\] Properties \\(E(X)\\) matrix: 1. \\(B=[b_1, ..., b_n]^T\\) constant-vector, \\(E(B)=B\\) 2. \\(E(cX)=cE(X)\\), \\(c\\) - constant term 3. \\(E(X+Y)=E(X)+E(Y)\\), \\(X\\) \\(Y\\) random variables vectors 4. \\(E(AX)=AE(X)\\) \\(\\) - matrix constant terms covariance random vector \\(X=[x_1,...,x_i]^T\\) \\(V(X)\\) (also might see another notation - \\(\\sum\\)): \\[V(X)=\\begin{bmatrix}     Cov(x_1, x_1) & \\dots & Cov(x_1,x_i) \\\\     \\vdots & \\ddots & \\vdots \\\\     Cov(x_i, x_1) & \\dots & Cov(x_i, x_i) \\\\ \\end{bmatrix}= \\begin{bmatrix}     Var(x_1) & \\dots & Cov(x_1,x_i) \\\\     \\vdots & \\ddots & \\vdots \\\\     Cov(x_i, x_1) & \\dots & Var(x_i) \\\\ \\end{bmatrix}\\] quadratic symmetric matrix. \\(X = [X_1]\\) (one-dimensional random variable) \\[V(X)=Cov(X_1,X_1)=Var(X_1)\\] \\(V(X)\\) can written random-vector \\(X\\) : \\[V(X)=E[(X-E(X))*(X-E(X))^T]\\] Properties \\(V(X)\\) matrix: 1. \\(V(cX)=c^2V(X)\\), \\(c\\) constant term 2. \\(V(X+B)=V(X)\\) \\(B\\) constant-vector 3. \\(V(AX)=AV(X)^T\\) \\(\\) constant matrix 4. \\(Cov(cX,zX)=cV(X)z^T\\)","code":""},{"path":[]},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"model","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Model","title":"Materials for CSRA students/interns","text":"formula linear regression \\(k\\) explanatory variables : \\[y_i = \\beta_0+\\sum_k{\\beta_kx_{,k}}+\\epsilon_i\\] \\(y\\) dependent variable (outcome) try explain/predict independent (explanatory) variables \\(x\\). Basically, equation two parts: Systematic: \\(\\beta_0+\\sum_k{\\beta_kx_{,k}}\\) Stochastic: \\(\\epsilon_i \\sim N(0,\\sigma^2)\\) stochastic part fully random. understand another way, let reformulate formula: \\[\\mu_i=\\beta_0+\\sum_k{\\beta_kx_{,k}}\\] \\[y_i \\sim N(\\mu_i,\\sigma^2)\\] words, model try predict average values dependent variable assuming mean \\(\\mu\\) conditional independent factors \\(x\\). estimate parameters \\(\\beta\\)? Turning technical issues, minimize RSS (Residuals Sum Squares) deviations modeled (predicted) values \\(y\\) hat (\\(\\hat y\\)) observed (real) values \\(y\\). Note, \\(\\hat y=\\beta_0+\\sum_k{\\beta_kx_{,k}}\\), can write RSS : \\[RSS=\\sum_i{(y_i-b_1x_{,1}-...b_kx_{,k}})^2\\] \\[RSS=\\sum_i{(y_i-\\hat y_i)^2}\\] Minimization sum (quadratic amount deviations modeled observable values) can done taking partial derivatives respect \\(\\beta_k\\) (lets write concise \\(\\theta=[\\beta_1, \\beta_2, ... \\beta_p]\\)) coefficients linear combination \\(X\\) (matrix explanatory variables). matrix following view: \\[\\begin{bmatrix}     x_{11} & \\dots & x_{1j} \\\\     \\vdots & \\ddots & \\vdots \\\\     x_{i1} & \\dots & x_{ij} \\\\ \\end{bmatrix}\\] columns \\(j\\) variables rows \\(\\) units. example, units countries (Russia, USA, France) variables population democracy level. \\[\\begin{bmatrix}     0.894 &  63715.22 \\\\     0.271 & 63715.22 \\\\     0.905 & 323348.65 \\\\ \\end{bmatrix}\\] Turning minimization respect \\(\\theta\\) parameters, system k equations form (example \\(k=1\\)): \\[\\sum_i{\\frac{\\partial RSS}{\\partial \\beta_1}}=\\sum_i{2*(-x_{,1})*(y_i-\\beta_1x_{,1}-\\beta_2x_{,2}-...)}=0\\] can rearranged (opening brackets dividing equations -2) : \\[\\sum_i{x_{,1}^2 \\beta_1}+\\sum_i{(x_{,2}x_{,1})\\beta_2}+...=\\sum_i{x_{,1}y_i}\\] terms linear algebra equation: \\[X^TX\\theta=X^Ty\\] one can find \\(\\theta\\) reformulating previous formula (multiply parts \\((X^TX)^{-1}\\) lefty, \\(^{-1}=\\) \\(\\) unit matrix): \\[\\theta = (X^TX)^{-1}X^Ty\\] equation one solution \\(det[X^TX]\\ne 0\\) (see Assumptions). full model : \\[y=X\\theta+\\epsilon\\] \\[y=\\theta^TX+\\epsilon\\]","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"assumptions-gauss-markov-theorem","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Assumptions (Gauss-Markov theorem):","title":"Materials for CSRA students/interns","text":"Homoscedasticity: \\(Var(\\epsilon|x)=const\\) multicollinearity: \\(Corr(x_1, x_2)\\neq0 \\\\) inflated SE, robust results (drop observation significantly change \\(\\theta\\) estimates). case perfect multicollinearity (\\(Corr=|1|\\), dummy variable trap - just opposite dummies model), find estimation \\(\\theta\\) (find inverse matrix \\(X^TX\\) due determinant equals 0) endogeneity: \\(Corr(\\epsilon_i|\\epsilon_j)=0\\) \\(E(\\epsilon_i|x_{,j})=0\\) Normality residuals \\(E(\\epsilon)=0\\) Thus, \\(\\epsilon_i \\sim ..d. N(0,\\sigma^2)\\), \\(..d\\) - identically independently distributed. Therefore, residuals covariance matrix \\(V(\\epsilon)=\\sigma^2I\\)","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"properties","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Properties:","title":"Materials for CSRA students/interns","text":"assumptions held, OLS estimation Best Linear Unbiased Estimator (BLUE). , : 1. efficient: min \\(Var(\\hat \\theta)\\) among possible linear unbiased estimates \\(\\theta\\) 2. unbiased: \\(E(\\hat \\theta)=\\theta\\) 3. consistent:\\[\\lim_{n\\\\inf}{\\sigma^2(X^{(n)T}X^{(n)})^{-1}_{jj}}=0\\] \\[\\lim_{n\\\\inf}{Var(\\hat \\theta_i^{(n)})}=0\\] \\(E(\\hat \\theta_i^{(n)})=\\theta_i\\) can just write: \\[\\lim_{n\\inf}{(\\hat \\theta^{(n)}_i-\\theta_i)}=0\\]","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"standard-errors-and-significance","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Standard errors and significance:","title":"Materials for CSRA students/interns","text":"identifying \\(\\hat{\\theta}\\) significant calculate variance \\(Var(\\hat{\\theta})\\). Lets find covariance matrix diagonal elements \\(Cov(\\theta_i,\\theta_i)=Var(\\theta_i)\\): \\[V(\\hat{\\theta})=\\hat{\\sigma}^2(X^TX)^{-1}\\]\\(\\hat{\\sigma}^2\\) estimation \\(Var(\\hat{\\epsilon})\\) estimated model \\(\\hat{Y}=X\\hat{\\theta}\\). estimation can done using statistic : \\[S^2=\\frac{RSS}{n-p}=\\frac{\\sum_i{(y_i-\\hat y_i)^2}}{n-p}\\] unbiased estimation \\(Var(\\epsilon)\\), \\(E(S^2)=Var(\\epsilon)\\). words, Sample Variance \\(\\epsilon\\). model intercept, \\(S^2\\) just usual sample variance \\(y\\). SE statistics calculation just \\(\\sqrt{diag[V(\\hat{\\theta})]}\\). statistic \\(\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}}\\) known distribution (t-distribution). use \\(\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}}\\) simply shows: \\[\\frac{\\hat{\\theta}-\\theta^0}{se_{\\hat{\\theta}}} \\sim t(n-p)\\]\\(\\hat \\theta^0\\) shows value \\(\\theta\\) \\(H_0\\). Usually 0, just \\(\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}}\\). possible use values \\(\\hat \\theta^0\\) test specific null hypotheses. example: \\[H_0: \\theta = 1\\] test statistic (works little bit complicated, logic basically like ): \\[\\frac{\\hat{\\theta}-\\theta^0}{se_{\\hat{\\theta}}}=\\frac{\\hat{\\theta}-1}{se_{\\hat{\\theta}}}\\] identifying confidence interval \\(\\hat\\theta\\): \\[\\hat\\theta_i-t_{1-\\alpha/2}\\sqrt{Var(\\hat\\theta_i)}, \\hat\\theta_i+t_{1-\\alpha/2}\\sqrt{Var(\\hat\\theta_i)}\\] words, population parameter \\(\\theta\\) lying estimated CI \\(100(1-\\alpha)\\)% probability.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"significance-of-the-model","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Significance of the model:","title":"Materials for CSRA students/interns","text":"One wants test significance \\(\\theta_i\\), whole model set estimated coefficients \\(\\theta\\). Thus, joint test needed, null hypothesis : \\[H_0: \\theta_0=\\theta_1=...=\\theta_i=0\\] Thus, alternative hypothesis least one coefficient \\(\\theta_i\\) zero. One possible approach tests joint \\(H_0\\) F-test. Assume linear model set coefficients \\(p\\) number observations \\(n\\). test statistic \\(F\\) : \\[F=\\frac{(RSS_{H_0}-RSS)/q}{RSS/(n-p)}=\\frac{ESS/(p-1)}{RSS/(n-p)} \\sim F(p-1,n-p)\\] test basically compare null model (intercept ) estimated model, \\(RSS\\) - residuals sum squares, \\(ESS\\) - explained sum squares (\\(TSS-RSS\\)). statistic \\(F\\) distribution \\(p-1\\) \\(n-p\\) degrees freedom \\(\\epsilon_i \\sim iid \\ N(0,\\sigma^2)\\). Note, first expression can used test joint hypothesis \\(H_0\\) coefficients, last one \\(ESS\\) can used \\(H_0\\) coefficients assumed 0. first expression useful, ex., comparing two null-models. Assume model: \\[y=\\theta_0+\\theta_1x_i+\\theta_2k_i + \\theta_3z_i+\\epsilon_i\\] want test hypothesis : \\[H_0:\\theta_2=\\theta_3=0\\] can use \\(F\\) test, \\(H_0\\) model \\(y_i=\\theta_0+\\theta_1x_i+\\varepsilon_i\\). parameter \\(q\\) number tested null coefficients (precisely number linear restrictions model). example \\(q=2\\).","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"endogeneity","dir":"Articles","previous_headings":"Econometrics > OLS aka linear regression","what":"Endogeneity","title":"Materials for CSRA students/interns","text":"Statistical definition: 1. \\(E(\\epsilon|X) \\ne 0\\) 2. \\(Corr(\\epsilon, X)\\ne0\\) words, \\(\\epsilon\\) independently distributed. Main sources endogeneity: Omitted variable problem. Omitted significant variable \\(C\\) (appropriate control variable) effect Y (\\(C \\Y\\)) effect X (\\(C \\X\\)) Consequence - biased result \\(X\\) model : \\(y=\\beta_0+\\beta_1x\\) \\(Y \\Z\\) \\(X \\Z\\) effect \\(X\\) \\(Y\\) Consequence - biased result \\(X\\) oue model : \\(y=\\beta_0+\\beta_1x+\\beta_2z\\) Reverse causality problem need controls (confounders)? Controls common variance (=effect) \\(X\\) (independent variable) \\(Y\\) (dependent variable). get less biased estimates \\(X\\) include controls, part common variance \\(X\\) \\(Y\\) due confounders, including “clean” common variance \\(X\\) \\(Y\\) “noise” produced factors. , “omitted variable bias” “backdoor” problem emerge resulting endogeneity biased, inconsistent inference.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"data-types","dir":"Articles","previous_headings":"Econometrics > Panel data","what":"Data types:","title":"Materials for CSRA students/interns","text":"Cross-section data - many units one time (GDP countries 2002): \\(y_i=y_{country}\\) Time-series data - one unit time (GDP Russia 2002 2010): \\(y_t=y_{year}\\) Panel data - units repeated time: \\(y_{,t}=y_{country,year}\\) Pooled data - panel data researcher consider time spatial dependencies Cross-section data Time-series data Panel data (cross-section + time-series) Problems panel data: cross-sectional correlations (across units) autocorrelation (time) problem ignoring spatial time effects data special case general problem, omitting variables (endogeneity) Aggregation bias (Sympson paradox) serial correlations inconsistent SE \\(\\\\) wrong statistical inference","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"fixed-effects-fe","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"Fixed-effects (FE)","title":"Materials for CSRA students/interns","text":"FE models can remove time-invariant omitted variables, unit-invariant omitted variables, variance outcome. ability FE model remove confounders side effect fact FE isolate particular dimensions variance data analyze. LSDV LSDV - Least Squares Dummy Variables model \\(N\\) cross-sectional/time units): \\[y_{,t}=\\beta_0+\\gamma_1d_{1,}+...+\\gamma_{(N-1)}d_{N-1,}+\\beta_1x_{,t}+\\varepsilon_{,t}\\] \\(d\\) specific binary variable modeling unit-specific intercept. set \\(d\\) countries want include FE cross-sectional dimension, \\(d_{,1}\\) 1 country USA 0 otherwise. model assumes coefficients units different intercepts. Intercept \\(\\beta_0\\) - average level \\(y\\) reference cross-sectional/time unit. \\(\\gamma\\) - difference intercept reference unit unit. average difference \\(y\\) unit reference category (also unit) variables equal. Error term structure: \\(\\varepsilon_{,t} = \\varepsilon_i + \\varepsilon_t\\) (cross-sectional variance + time dimension variance). FE models show? See Kropko Kubinec (2020) Unit FE: represents average effect unit-increase x y variable changes time, generalized cases (GDP increases country time, quality democracy change time?) Time FE: time FE coefficients represent average effect unit-increase x y variable changes case case, generalized across time points (much democratic wealthier countries poorer countries point time?)","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"random-effects-re","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"Random-effects (RE)","title":"Materials for CSRA students/interns","text":"Instead usual OLS equation LSDV OLS can use RE model random intercept: \\[y_{ij}=\\beta_{0j}+\\beta_1 x_{ij}+r_{ij}\\] \\[\\beta_{0j}=\\gamma_{00}+u_{0j}\\] fist equation refers first-level (individuals \\(\\)), second refers second-level (clusters \\(j\\)). \\(r_{ij}\\) - individual-level error term, \\(u_{0j}\\) - cluster-level error term modeled random error cluster’s intercept individual level (random intercept). \\(W_j\\) affects intercept \\(\\gamma_{01}\\) coefficient. \\(\\gamma_{00}\\) - overall intercept. estimated intercepts assumed random drawings normal distribution thus can easily extended --sample groups Model Assumptions: \\(r_{ij} \\sim ..d. N(0, \\sigma^2)\\), independent \\(X\\): \\(E(r_{ij}|X,W)=0 \\\\) first-level exogeneity \\(u_{0j} \\sim ..d. N(0, \\tau_{00})\\), independent \\(X\\): \\(E(u_{0j}|X,W)=0 \\\\) second-level exogeneity \\(Corr(r_{ij},u_{0j})=0\\) can combine -mentioned equations one: \\[y_{ij}=\\gamma_{00}+\\beta_1 x_{ij}+(u_{0j}+r_{ij})\\] Thus, \\(\\gamma_{00}\\) - usual intercept, \\(\\varepsilon_{ij}\\) decomposed across two independent source Random Variance - within (individual level) \\(r_{ij}\\) (clusters level) \\(u_{0j}\\) clusters.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"fe-vs--re","dir":"Articles","previous_headings":"Econometrics > Panel data > What to do?","what":"FE vs. RE","title":"Materials for CSRA students/interns","text":"majority cases FE better RE due strict assumptions. assumptions held one chooses FE, estimates less efficient. However, one chooses RE instead FE assumptions true, estimates biased inconsistent. noted, strong assumptions endogeneity (individual + cluster endogeneity problem possible problem omitted variables either first second levels). However, lot cases RE appropriate: data hierarchy (nested clusters) want separate within variance cluster’s variables -> FE might perfect collinearity situation just 1 year observation (cluster unique value GDP -> perfect multicollinearity) sample fully random (surveys) cases - FE: “without analyzing contextual effects coefficient heterogeneity across higher-level units, ‘good old’ simple OLS regression cluster-robust standard errors fixed effects higher levels retained valid alternative MLM.” (Oshchepkov Shirokanova 2022) size clusters (number observation ) small better stable","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"limited-dv","dir":"Articles","previous_headings":"Econometrics","what":"Limited DV","title":"Materials for CSRA students/interns","text":"Limited Dependent Variables variables continuous, binary ordinal variables specific distributions. OLS fails predict model catch distributions. case binary data, OLS predicts 0.7, -0.3, 123 theoretically impossible values (lovers linear probability models). , linear estimation appropriate , finally, least-squares estimation bad approach.","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"logistic-regression","dir":"Articles","previous_headings":"Econometrics > Limited DV","what":"Logistic regression","title":"Materials for CSRA students/interns","text":"Logistic regression models binary dependent variable using Logit link. Moreover, terms probabilities. Assume binary dependent variable \\(Y\\) follows Bernoulli distribution (special case binomial distribution 1 trial): \\[Y\\sim (\\pi[X])\\] probability getting “success” (“1”) \\(\\pi\\) depends vector parameters \\(X\\). probability calculated logistic function: \\[\\pi(X)=\\frac{exp(X)}{1+exp(X)}\\] \\(\\pi\\) probability measures 0 1. One can see equation indeed \\(\\pi(x)\\) takes positive values (\\(exp\\)) changes 0 1 (denominator always larger numerator addition unit). can rewrite function “regressive” way: \\[\\pi(X)=\\frac{exp(X\\theta)}{1+exp(X\\theta)}=\\frac{1}{1+exp(-X\\theta)}\\] know probability function Bernoulli distribution : \\[P(Y_i|\\pi_i)=\\pi_i^{Y_i}(1-\\pi_i)^{(1-Y_i)}\\] try estimate . analytical solution optimization, iterative process used Maximum Likelihood (ML) estimator \\(L\\) assumption observations independence: \\[L=\\prod_i^n{\\pi_i^{y_i}(1-\\pi_i)^{1-y_i}}\\] \\(\\pi\\) calculated previous equation. optimization process product function sophisticated, make \\(L\\) logarithmization take log-likelihood: \\[l=\\sum_i^n [y_iln(\\pi_i)+(1-y_i)ln(1-\\pi_i)]\\] \\[l=\\sum_i^n[y_iln(\\frac{1}{1+exp(-X\\theta)})+(1-y_i)(\\frac{1}{1+exp(-X\\theta)})]\\] \\[l=\\sum_i^n [y_i X\\theta-ln(1+exp(X\\theta))]\\] estimation process simple, going discuss now. Simply put, ML works finding value \\(\\hat{\\theta}\\) gives maximum value function \\(l\\). \\(\\hat{\\theta}\\) consistent asymptotically efficient except perfect collinearity \\(X\\) perfect discrimination 0 1. covariance matrix estimated : \\[V(\\hat{\\theta})=^{-1}(\\hat{\\theta})\\] \\(\\) information matrix calculated : \\[(\\hat{\\theta})=X^T \\hat{W}X\\] \\(\\hat{W}\\) estimated variance \\(Y\\) following diagonal matrix \\(n*n\\): \\[\\begin{bmatrix}     \\pi_{1}(1-\\pi_{1}) & \\dots & 0 \\\\     \\vdots & \\ddots & \\vdots \\\\     0 & \\dots & \\pi_{n}(1-\\pi_{n}) \\\\ \\end{bmatrix}\\] Thus, finally : \\[V(\\hat{\\theta})=[\\sum_i^n{\\pi_i(1-\\pi_i)X^TX}]^{-1}=\\] \\[=(X^T \\hat{W}X)^{-1}\\] standard errors just squared root diagonal \\(V(\\hat{\\theta})\\) test statistic \\(\\hat{\\theta}\\) follows standard normal distribution calculated : \\[\\frac{\\hat{\\theta}}{se_{\\hat{\\theta}}} \\sim N(0,1)\\]","code":""},{"path":"https://vadvu.github.io/csra/articles/student.html","id":"rare-events-data","dir":"Articles","previous_headings":"","what":"Rare events data","title":"Materials for CSRA students/interns","text":"Revolutions, civil wars, defaults, coups rare events data can considered marginal unbalanced binary data due strong predominance one class (event). Therefore, specific methods required analyze (King Zeng 2001). One method logistic regression special version ML estimator (Kosmidis Firth 2009; King Zeng 2001) make consistent less biased case imbalanced data problem. One approach involves deliberately removing significant number ’0’s balance number observations classes (can achieved via mathcing procedures). approach enables use classical logistic regression without concern imbalance. nonparametric method, one can use random forest model quantile classifier (O’Brien & Ishwaran, 2019), specifically designed classifying unbalanced data. important note method allows avoidance assumptions form relationship. parametric models, authors assumed make assumption linearity, method, one can change form assumption simple operations variable, logarithmization representing factor polynomial. approach can lead reasonably accurate estimates. Next, discuss approach implemintation.","code":""},{"path":[]},{"path":"https://vadvu.github.io/csra/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vadim Ustyuzhanin. Author, maintainer.","code":""},{"path":"https://vadvu.github.io/csra/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ustyuzhanin V (2024). csra: Analysis count data. R package version 1.2.0, https://vadvu.github.io/csra/.","code":"@Manual{,   title = {csra: Analysis of count data},   author = {Vadim Ustyuzhanin},   year = {2024},   note = {R package version 1.2.0},   url = {https://vadvu.github.io/csra/}, }"},{"path":"https://vadvu.github.io/csra/index.html","id":"csra","dir":"","previous_headings":"","what":"Analysis of count data","title":"Analysis of count data","text":"csra package functions used CSRA staff analyze political events. Now just functions (one demo stage now - better say, development stage), can used basic analysis. Additionally, near future new features added, see news section.","code":""},{"path":"https://vadvu.github.io/csra/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analysis of count data","text":"can install development version csra GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"vadvu/csra\")"},{"path":"https://vadvu.github.io/csra/index.html","id":"tutorial","dir":"","previous_headings":"","what":"Tutorial","title":"Analysis of count data","text":"examples csra usage one can find website Get started section. detailed information function can found section website.","code":""},{"path":"https://vadvu.github.io/csra/index.html","id":"contact-information","dir":"","previous_headings":"","what":"Contact Information","title":"Analysis of count data","text":"comments csra (suggestions development, bug fixes, etc.), please, feel free contact via email: vvustiuzhanin@yandex.ru","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":null,"dir":"Reference","previous_headings":"","what":"U-shape test for rare events logistic regression — U_shape_test","title":"U-shape test for rare events logistic regression — U_shape_test","text":"U-shape test rare events logistic regression","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"U-shape test for rare events logistic regression — U_shape_test","text":"","code":"U_shape_test(   data,   dep,   ind,   cnt,   mod = \"brglm\",   boot = c(\"none\", \"nonparam\", \"factor\"),   factor = NULL,   n = 1000,   HC = T,   const = T,   table_remove = NULL,   plot = F,   tab_save = F )"},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"U-shape test for rare events logistic regression — U_shape_test","text":"data Dataframe dep Character. Dependent variable. ind Character. Independent variable. cnt Vector characters names control variables. mod Character. Type model (now just brglm supported) boot Character. middle point \"lines\" calculated via bootstrap? - \"none\", yes - one can choose bootstrap type factor Character. boot = \"factor\". n Number bootstrap draws HC Logical. heteroscedasticity-consistent SE used? const Logical. constant included models? table_remove Vector variables names excluded regression table. plot Logical. plot depicted? tab_save Logical. table saved? yes - table saved working directory.","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"U-shape test for rare events logistic regression — U_shape_test","text":"Plot regression table u-shape test summary.","code":""},{"path":"https://vadvu.github.io/csra/reference/U_shape_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"U-shape test for rare events logistic regression — U_shape_test","text":"Lind, J. T., & Mehlum, H. (2010). without U? appropriate test U‐shaped relationship. Oxford bulletin economics statistics, 72(1), 109-118. Simonsohn, U. (2018). Two lines: valid alternative invalid testing U-shaped relationships quadratic regressions. Advances Methods Practices Psychological Science, 1(4), 538-555.","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":null,"dir":"Reference","previous_headings":"","what":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"Data revolutionary campaigns democracy index, 1901-2019","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"","code":"datex"},{"path":[]},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"datex-a-data-frame-with-rows-and-columns-","dir":"Reference","previous_headings":"","what":"datex A data frame with 9,836 rows and 6 columns:","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"iso3 Country code \"iso3c\" format year Year NVC_1.3_NONVIOL Binary indicator. protestors primary use nonviolent tactic? 1 = Yes NVC_1.3_VIOL Binary indicator. protestors primary use violent tactic? 1 = Yes VDEM_v2x_polyarchy Electoral democracy index (0,1) V-Dem project VDEM_v2x_polyarchy_lag Electoral democracy index (0,1) time t-1 country ","code":""},{"path":"https://vadvu.github.io/csra/reference/datex.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data of revolutionary campaigns and democracy index, 1901-2019 — datex","text":"NAVCO 1.3, VDEM","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":null,"dir":"Reference","previous_headings":"","what":"Analysis of a binary data by dividing independent into equal parts — equalparts","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"Analysis binary data dividing independent equal parts","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"","code":"equalparts(   data,   independent,   lag_independent = FALSE,   lag_code,   lead = TRUE,   dependent,   n = 6,   nominal_or_percent = \"nominal\",   bar_or_scatter = \"bar\",   regline = TRUE,   range_bars = FALSE,   conf_bars = TRUE,   return_data = FALSE,   save_plot = FALSE,   name_save_plot = \"plot\" )"},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"data Dataframe independent Character. Independent variable. lag_independent Logical. independent variable lagged 1 time-unit? lag_code Character. Passed lag_independent False. name variable dataframe subject data. ex., country name, iso3 etc. lead Logical. Passed lag_independent False. lead used instead lag? Lead used case, data's top earlier time units (ex., 2022, 2021, 2020, ...). Lag used data's top starts later time units (1900, 1901, ...). dependent Character. Dependent variable. n Int. Number equal parts independent variable divided. nominal_or_percent Logical. output y-axis (intensity dependent variable) percents nominal values? want scatter plot automatically changed nominal. bar_or_scatter Character 2 possible values: \"bar\", \"scatter\". Type figure plotted. regline Logical. linear regression line plotted? range_bars Logical. range bars shown? Range depicts min max value independent variable divided group. conf_bars Logical. confidence bars shown? depict 95%CI binary dependent variable. return_data Logical. returned data (table)? False, plot returned. save_plot Logical. plot saved working directory? name_save_plot Character. Passed save_plot False. Name plot saving.","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"Plot (bar scatter) dataframe. dataframe following columns: parts: number equal part. first lowest values, last highest values Freq_0: number 0 cases dependent variable Freq_1: number 1 cases dependent variable means: mean independent variable specific equal part min: min value independent variable specific equal part max: max value independent variable specific equal part prc5: 5% percentile independent variable specific equal part prc95: 95% percentile independent variable specific equal part low95CI: lower border 95% CI Freq_1 high95CI: higher border 95% CI Freq_1","code":""},{"path":"https://vadvu.github.io/csra/reference/equalparts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analysis of a binary data by dividing independent into equal parts — equalparts","text":"","code":"data(\"datex\") equalparts(data = datex, independent = 'VDEM_v2x_polyarchy_lag', lag_independent = FALSE, dependent = 'NVC_1.3_NONVIOL', n = 6, bar_or_scatter = 'scatter', regline= TRUE, return_data = FALSE, conf_bars = TRUE, range_bars = FALSE, save_plot = FALSE)   equalparts(data = datex, independent = 'VDEM_v2x_polyarchy', lag_independent = TRUE, lag_code = \"iso3\", lead = TRUE, dependent = 'NVC_1.3_NONVIOL', n = 10, bar_or_scatter = 'bar', nominal_or_percent = \"percent\", return_data = FALSE, conf_bars = TRUE, save_plot = TRUE, name_save_plot = \"figure1\")"},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Goldstone claasification of regime types based on Polity-V variables — goldclass","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"Goldstone claasification regime types based Polity-V variables","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"","code":"goldclass(exrec, parcomp)"},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"exrec array EXREC variable Polity-V project parcomp array PARCOMP variable Polity-V project","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"array Goldstone classification: 1 = full autocracy 2 = partial autocracy 3 = partial democracy 4 = partial democracy factionalism 5 = full democracy","code":""},{"path":"https://vadvu.github.io/csra/reference/goldclass.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Goldstone claasification of regime types based on Polity-V variables — goldclass","text":"Goldstone, J.., Bates, R.H., Epstein, D.L., Gurr, T.R., Lustik, M.B., Marshall, M.G., Ulfelder, J. & Woodward, M. (2010). Global Model Forecasting Political Instability. American Journal Political Science, 54, 190–208.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://vadvu.github.io/csra/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":null,"dir":"Reference","previous_headings":"","what":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"database revolutionary events 21st century prepared within framework project “Quantitative Analysis Forecasting Risks Socio-Political Destabilization Countries Afrasian Macrozone Instability” supported Russian Science Foundation (project . 18-18-00254-P). database describes revolutionary events 21st century various characteristics: chronological, geographical, type protestors' tactics, purpose degree success.","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"","code":"revolutions"},{"path":[]},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"revolutions-a-data-frame-with-event-as-unit-of-analysis-","dir":"Reference","previous_headings":"","what":"revolutions A data frame with event as unit of analysis.","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"n unique episode number start_year event start year end_year event end year country country name iso3c three-letter ISO 3166-1 alpha-3 (iso3c) country code region region country event took place belongs (UN Subregion classification) successful complete success (1 = yes, 0 = ) limited limited success (1 = yes, 0 = ) failed fail (1 = yes, 0 = ) ongoing episode still ended? (1 = yes, 0 = ). Note, episode can ongoing \"success\" coding preliminary estimate. armed armed tactic: fabric weapons (1 = yes, 0 = ) unarmed unarmed tactic: nonviolent resistance improvised weapons - sticks, stones (1 = yes, 0 = ) regime_change goal regime change (1 = yes, 0 = ) islamistic goal connected Islam (1 = yes, 0 = ). Note, feature usually goes regime change goal democratic goal establish/improve democratic institutions (1 = yes, 0 = ). Note, feature usually goes regime change goal social goal primary social, firstly connected life-conditions (1 = yes, 0 = ) separatism goal gain independence/autonomy (1 = yes, 0 = ) goal (1 = yes, 0 = ). Can overlapped mentioned goal types coupvolution event ended \"End game Coup\"? (1 = yes, 0 = ) revolutions event pure revolution (mass mobilization, aim overthrough regime)? (1 = yes, 0 = ) revolutions_plus_question event pure revolution, can still considered revolutionary movement? (1 = yes, 0 = ) types event including quasi-revolutionary events (one unique value = 1) ethnic episode connected ethnic cleaveges? (1 = yes, 0 = )","code":""},{"path":"https://vadvu.github.io/csra/reference/revolutions.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Revolutions dataset, 2000-2022 (Version 9) — revolutions","text":"Center Stability Risk Analysis","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonparametric test for comparing means in 2 groups — sdiff","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"Nonparametric test comparing means 2 groups","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"","code":"sdiff(x, y, n = 1000)"},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"x Numeric array observations first group. y Numeric array observations second group. n Number simulations constriction Null hypothesis area. Default n=1000","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"ggplot","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"nonparametric test (alternative t-test) based Monte Carlo Simulations. idea straightforward. First, initial difference groups counted. Null hypothesis - difference equal zero, alternative hypothesis - difference significantly different zero. test hypothesis, iterative procedure created values groups randomly mixed (.e. observation can randomly assigned one groups). Due randomness, difference mean mixed groups zero. thousand procedures, construct distribution resulting differences simply compare observed difference.","code":""},{"path":"https://vadvu.github.io/csra/reference/sdiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonparametric test for comparing means in 2 groups — sdiff","text":"","code":"x = rnorm(1000, 10, 10) y = rnorm(1000, 11, 2) sdiff(x, y, n = 1000) #> Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. #> ℹ Please use `after_stat(density)` instead. #> ℹ The deprecated feature was likely used in the csra package. #>   Please report the issue to the authors. #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"https://vadvu.github.io/csra/news/index.html","id":"csra-112","dir":"Changelog","previous_headings":"","what":"csra 1.1.2","title":"csra 1.1.2","text":"fixes U-shape, adding goldclass function. Plans: 1. Conceptually change U-shape 2. Add example section usage packages (students)","code":""}]
